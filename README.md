# ğŸ§  RAG Agent - Obsidian Knowledge Assistant

A sophisticated RAG (Retrieval-Augmented Generation) system that transforms your Obsidian vault into an intelligent, conversational knowledge assistant. Upload your notes and chat with your personal knowledge base using AI.

## âœ¨ Features

- **ğŸ¨ ChatGPT-like Interface**: Modern Streamlit web app with elegant white/green design
- **ğŸ“ Obsidian Integration**: Upload your Obsidian vault as a ZIP file for instant processing
- **ğŸ¤– Dual AI Modes**: 
  - **Q&A Mode**: Ask specific questions and get direct answers
  - **Summarize Mode**: Request comprehensive summaries on any topic
- **ğŸ” Smart Retrieval**: Advanced document retrieval with source attribution
- **âš¡ Real-time Processing**: Automatic document indexing and embedding generation
- **ğŸ“± Responsive Design**: Clean, modern interface that works on all devices

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Google AI API Key (for Gemini)

### Installation & Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/notes-rag-agent.git
   cd notes-rag-agent
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv ragagent
   
   # Windows
   ragagent\Scripts\activate
   
   # macOS/Linux
   source ragagent/bin/activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up API key**:
   - Get your Google AI API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
   - Create a `.env` file in the project root:
     ```env
     GOOGLE_API_KEY=your_google_api_key_here
     ```

5. **Start the application**:
   
   **Option A: Automated (Recommended)**
   ```bash
   # Windows
   start_streamlit.bat
   
   # Cross-platform
   python start_streamlit.py
   ```
   
   **Option B: Manual**
   ```bash
   # Terminal 1: Start Backend
   cd src
   python fastapi_backend.py
   
   # Terminal 2: Start Frontend
   streamlit run streamlit_app.py
   ```

6. **Open your browser** and navigate to `http://localhost:8501`

## ğŸ“± How to Use

### 1. Upload Your Obsidian Vault
- Export your Obsidian vault as a ZIP file
- Use the elegant upload interface to select your file
- Wait for automatic processing and indexing

### 2. Select AI Mode
- **Q&A Mode**: Perfect for specific questions about your notes
- **Summarize Mode**: Great for comprehensive topic overviews

### 3. Start Chatting
- Ask questions in natural language
- View source documents in the sidebar
- Switch between modes anytime during conversation

### 4. Explore Your Knowledge
- Get instant answers from your personal knowledge base
- See which documents contributed to each response
- Build on previous conversations seamlessly

## ğŸ—ï¸ Architecture

### Backend (FastAPI + LangChain)
- **ğŸ”§ FastAPI Server**: RESTful API with automatic documentation
- **ğŸ“„ Document Processing**: Markdown parsing with Obsidian link cleaning
- **ğŸ§  LangChain Integration**: Advanced RAG pipeline with LangGraph
- **ğŸ” Vector Search**: ChromaDB for semantic similarity search
- **ğŸ¤– AI Models**: Google Gemini for generation, HuggingFace for embeddings

### Frontend (Streamlit)
- **ğŸ¨ Modern UI**: ChatGPT-inspired interface with custom CSS
- **ğŸ“± Responsive Design**: Clean white/green theme
- **ğŸ”„ Real-time Updates**: Instant chat responses and document display
- **ğŸ“Š State Management**: Session-based conversation history

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file in the project root:
```env
GOOGLE_API_KEY=your_google_api_key_here
```

### API Endpoints
- `POST /upload-vault` - Upload and process Obsidian vault ZIP file
- `POST /rag_query` - Send queries with mode selection (qa/summarize)
- `POST /clear-documents` - Clear all uploaded documents

### Customization
- **Embedding Model**: Change in `src/rag_indexer.py` (default: all-MiniLM-L6-v2)
- **LLM Model**: Modify in `src/rag_chain_config.py` (default: gemini-2.5-flash)
- **Chunk Sizes**: Adjust in `src/rag_indexer.py` for different document sizes
- **UI Theme**: Customize colors in `streamlit_app.py` CSS section

## ğŸ“ Project Structure

```
notes-rag-agent/
â”œâ”€â”€ src/                      # Backend source code
â”‚   â”œâ”€â”€ fastapi_backend.py    # FastAPI application & API endpoints
â”‚   â”œâ”€â”€ rag_chain_config.py   # RAG pipeline & AI modes
â”‚   â””â”€â”€ rag_indexer.py        # Document processing & embeddings
â”œâ”€â”€ streamlit_app.py          # Streamlit frontend application
â”œâ”€â”€ start_streamlit.bat       # Windows startup script
â”œâ”€â”€ start_streamlit.py        # Cross-platform startup script
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ uploaded_documents/       # Processed vault storage (auto-created)
â”œâ”€â”€ chroma_db/               # Vector database storage (auto-created)
â””â”€â”€ README.md                # Project documentation
```

## ğŸ¯ Use Cases

- **ğŸ“š Research**: Query your research notes and papers
- **ğŸ“ Study Aid**: Get summaries of complex topics from your notes
- **ğŸ’¡ Knowledge Discovery**: Find connections between different concepts
- **ğŸ“– Personal Wiki**: Turn your Obsidian vault into a searchable knowledge base
- **ğŸ“ Academic Work**: Quickly reference and cite your note sources

## ğŸ› ï¸ Development

### Tech Stack
- **Backend**: FastAPI, LangChain, ChromaDB, Google Gemini
- **Frontend**: Streamlit with custom CSS
- **Embeddings**: HuggingFace Sentence Transformers
- **Vector DB**: ChromaDB with persistent storage

**Transform your notes into an intelligent knowledge companion! ğŸ§ âœ¨**
